{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "rcParams['figure.figsize'] = 16, 10\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boxx  \n",
    "train_js = boxx.loadjson('instances_train2019.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df = pd.DataFrame(train_js['categories'])\n",
    "annotations_df = pd.DataFrame(train_js['annotations'])\n",
    "annotations_df=annotations_df.rename(columns={'id':'annotation_id'})\n",
    "images_df = pd.DataFrame(train_js['images'])\n",
    "images_df=images_df.rename(columns={'id':'image_id'})\n",
    "categories_df=categories_df.rename(columns={'id':'category_id'})\n",
    "temp=pd.merge(annotations_df,images_df,how=\"inner\",on=\"image_id\")\n",
    "train=pd.merge(temp,categories_df,how=\"left\",on=\"category_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "src_dir = \"train2019/\"#'OneDrive - Institute of Business Administration/archive/images/train2019'\n",
    "dst_dir = \"images/train2019/\"\n",
    "for jpgfile in train['file_name']:\n",
    "    src_path = os.path.join(src_dir,jpgfile)\n",
    "    if not os.path.exists(dst_dir): os.makedirs(dst_dir)\n",
    "    #print(src_path)\n",
    "    #print(jpgfile)\n",
    "    shutil.copy(src_path, dst_dir)\n",
    "    #print(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boxx  \n",
    "val_js = boxx.loadjson('instances_val2019.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df_val = pd.DataFrame(val_js['categories'])\n",
    "annotations_df_val = pd.DataFrame(val_js['annotations'])\n",
    "images_df_val = pd.DataFrame(val_js['images'])\n",
    "images_df_val=images_df_val.rename(columns={'id':'image_id'})\n",
    "categories_df_val=categories_df_val.rename(columns={'id':'category_id'})\n",
    "temp=pd.merge(annotations_df_val,images_df_val,how=\"inner\",on=\"image_id\")\n",
    "val=pd.merge(temp,categories_df_val,how=\"left\",on=\"category_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "src_dir = \"val2019/\"#'OneDrive - Institute of Business Administration/archive/images/train2019'\n",
    "dst_dir = \"images/val2019/\"\n",
    "for jpgfile in set(val['file_name']):\n",
    "    src_path = os.path.join(src_dir,jpgfile)\n",
    "    if not os.path.exists(dst_dir): os.makedirs(dst_dir)\n",
    "    #print(src_path)\n",
    "    #print(jpgfile)\n",
    "    shutil.copy(src_path, dst_dir)\n",
    "    #print(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "(set(val['name'])) #list of all labels in val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_type, dtf):\n",
    "  #print(dtf[0:1])\n",
    "  images_path = Path(f\"images/{dataset_type}\")\n",
    "  images_path.mkdir(parents=True, exist_ok=True)\n",
    "  labels_path = Path(f\"labels/{dataset_type}\")\n",
    "  labels_path.mkdir(parents=True, exist_ok=True)\n",
    "  for idx,row in dtf.iterrows():\n",
    "    #print(row)\n",
    "    label_name = f\"{row['file_name'].split('.')[0]}.txt\"\n",
    "    with (labels_path / label_name).open(mode=\"a\") as label_file:\n",
    "        category_idx = row['category_id']\n",
    "        label_file.write(\n",
    "           f\"{category_idx} {(row['point_xy'][0])/row['width']} {(row['point_xy'][1])/row['height']} {(row['bbox'][2])/row['width']} {(row['bbox'][3])/row['height']}\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset( 'train2019', train)\n",
    "create_dataset('val2019', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to be run for training on terminal\n",
    "\n",
    "#python train.py --img 640 --batch 4 --epochs 3 --data ./data/rpc.yaml --cfg ./models/yolov5l.yaml --weights yolov5l.pt --name yolov5l_rpc --cache"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
